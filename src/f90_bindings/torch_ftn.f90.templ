! Copyright (c) 2021 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
! MIT License
! 
! Permission is hereby granted, free of charge, to any person obtaining a
! copy of this software and associated documentation files (the "Software"),
! to deal in the Software without restriction, including without limitation
! the rights to use, copy, modify, merge, publish, distribute, sublicense,
! and/or sell copies of the Software, and to permit persons to whom the
! Software is furnished to do so, subject to the following conditions:
! 
! The above copyright notice and this permission notice shall be included in
! all copies or substantial portions of the Software.
! 
! THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
! IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
! FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
! THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
! LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
! FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
! DEALINGS IN THE SOFTWARE.

#include "defines.inc"

module torch_ftn

    use iso_c_binding
    use iso_fortran_env

#ifdef _OPENACC
    use openacc
#endif

    implicit none

    public torch_module, torch_pymodule, torch_tensor, torch_tensor_wrap
           
    type :: torch_module
    private
        type(c_ptr) :: handle = c_null_ptr
        type(c_ptr) :: h_optimizer
    contains
        procedure :: load                 => torch_module_load
        procedure :: forward              => torch_module_forward
        procedure :: train                => torch_module_train
        procedure :: create_optimizer_sgd => torch_module_create_optimizer_sgd
        procedure :: save                 => torch_module_save
        final     :: torch_module_free
    end type

    type :: torch_pymodule
    private
        type(c_ptr) :: handle = c_null_ptr
    contains
        procedure :: load                 => torch_pymodule_load
        procedure :: forward              => torch_pymodule_forward
        procedure :: train                => torch_pymodule_train
        procedure :: save                 => torch_pymodule_save
        final     :: torch_pymodule_free
    end type

    type :: torch_tensor
    private
        type(c_ptr) :: handle   = c_null_ptr
        type(c_ptr) :: host_ptr = c_null_ptr 
        type(c_ptr) :: dev_ptr  = c_null_ptr 
        logical     :: is_acc_mapped
        integer     :: acc_mapped_size

    contains      
        procedure :: get_handle => torch_tensor_get_handle

        final :: torch_tensor_free

        generic :: from_array   => &
<%          torch_tensor_from_{dims.rank}_{dtype.name}
        generic :: to_array     => &
<%          torch_tensor_to_{dims.rank}_{dtype.name}

        procedure, private :: &
<%          torch_tensor_from_{dims.rank}_{dtype.name}, torch_tensor_to_{dims.rank}_{dtype.name}
    end type

    type :: torch_tensor_wrap
    private
        type(c_ptr) :: handle = c_null_ptr
    contains  
        procedure :: create     => torch_tensor_wrap_create
        procedure :: add_tensor => torch_tensor_wrap_add_tensor 

        generic   :: add_scalar => &
<%(dtype)   torch_tensor_wrap_add_scalar_{dtype.name}
        procedure, private :: &
<%(dtype)   torch_tensor_wrap_add_scalar_{dtype.name}

        generic   :: add_array  => &
<%          torch_tensor_wrap_add_array_{dims.rank}_{dtype.name}
        procedure, private :: &
<%          torch_tensor_wrap_add_array_{dims.rank}_{dtype.name}

        procedure :: clear => torch_tensor_wrap_clear
        final     :: torch_tensor_wrap_free
    end type

    ! Exposed flags and constants
    integer, parameter :: module_use_device = TORCH_FTN_MODULE_USE_DEVICE
    public module_use_device
    
    private

    interface
        subroutine torch_throw_cpp(message) &
            bind(c, name="torch_throw_cpp")
            import c_char
            character(c_char), intent(in)        :: message(*)
        end subroutine
    end interface

    !!======================================================================================
    !! Module-related C bindings
    !!======================================================================================

    interface
        subroutine torch_module_load_cpp(handle, file_name, flags) &
            bind(c, name="torch_module_load_cpp")
            
            import c_ptr, c_char, c_int
            type(c_ptr),       intent(inout)     :: handle
            character(c_char), intent(in)        :: file_name(*)
            integer(c_int),    intent(in), value :: flags
        end subroutine
    end interface

    interface
        subroutine torch_module_save_cpp(handle, file_name) &
            bind(c, name="torch_module_save_cpp")
            
            import c_ptr, c_char
            type(c_ptr),       intent(in), value :: handle
            character(c_char), intent(in)        :: file_name(*)
        end subroutine
    end interface


    interface
        subroutine torch_module_forward_cpp(module, inputs, output, flags) &
            bind(c, name="torch_module_forward_cpp")

            import c_ptr, c_int
            type(c_ptr),    intent(in),   value :: module
            type(c_ptr),    intent(in),   value :: inputs
            type(c_ptr),    intent(inout)       :: output
            integer(c_int), intent(in),   value :: flags
        end subroutine
    end interface

    interface
        subroutine torch_module_train_cpp(module, inputs, target, optimizer, loss) &
            bind(c, name="torch_module_train_cpp")

            import c_ptr, c_float
            type(c_ptr),    intent(in), value :: module
            type(c_ptr),    intent(in), value :: inputs
            type(c_ptr),    intent(in), value :: target
            type(c_ptr),    intent(in), value :: optimizer
            real(c_float),  intent(out)       :: loss
        end subroutine
    end interface
    
    interface
        subroutine torch_optimizer_create_sgd_cpp(handle, module, lr) &
            bind(c, name="torch_optimizer_create_sgd_cpp")

            import c_ptr, c_float
            type(c_ptr),    intent(inout)     :: handle
            type(c_ptr),    intent(in), value :: module
            real(c_float),  intent(in), value :: lr
        end subroutine
    end interface

    interface
        subroutine torch_module_free_cpp(handle) &
            bind(c, name="torch_module_free_cpp")
            
            import c_ptr
            type(c_ptr), intent(in), value :: handle
        end subroutine
    end interface

    !!======================================================================================
    !! PyModule-related C bindings
    !!======================================================================================

    interface
        subroutine torch_pymodule_load_cpp(handle, file_name) &
            bind(c, name="torch_pymodule_load_cpp")
            
            import c_ptr, c_char
            type(c_ptr),       intent(inout)     :: handle
            character(c_char), intent(in)        :: file_name(*)
        end subroutine
    end interface

    interface
        subroutine torch_pymodule_forward_cpp(module, inputs, output) &
            bind(c, name="torch_pymodule_forward_cpp")

            import c_ptr
            type(c_ptr),    intent(in),   value :: module
            type(c_ptr),    intent(in),   value :: inputs
            type(c_ptr),    intent(inout)       :: output
        end subroutine
    end interface


    interface
        subroutine torch_pymodule_train_cpp(module, inputs, target, is_completed, loss) &
            bind(c, name="torch_pymodule_train_cpp")

            import c_ptr, c_bool, c_float
            type(c_ptr),     intent(in), value :: module
            type(c_ptr),     intent(in), value :: inputs
            type(c_ptr),     intent(in), value :: target
            logical(c_bool), intent(out)       :: is_completed
            real(c_float),   intent(out)       :: loss
        end subroutine
    end interface


    interface
        subroutine torch_pymodule_save_cpp(module, file_name) &
            bind(c, name="torch_pymodule_save_cpp")

            import c_ptr, c_char
            type(c_ptr),       intent(in), value :: module
            character(c_char), intent(in)        :: file_name(*)
        end subroutine
    end interface


    interface
        subroutine torch_pymodule_free_cpp(module) &
            bind(c, name="torch_pymodule_free_cpp")

            import c_ptr
            type(c_ptr), intent(in), value :: module
        end subroutine
    end interface

    !!======================================================================================
    !! Tensor-related C bindings
    !!======================================================================================

    interface
        subroutine torch_tensor_from_array_cpp( &
            handle, array, arr_rank, arr_shape, elem_type, elem_size) &
            bind(c, name="torch_tensor_from_array_cpp")

            import c_ptr, c_int
            type(c_ptr),    intent(out)       :: handle
            type(c_ptr),    intent(in), value :: array
            integer(c_int), intent(in), value :: arr_rank
            integer(c_int), intent(in)        :: arr_shape(arr_rank)
            integer(c_int), intent(in), value :: elem_type
            integer(c_int), intent(in), value :: elem_size
        end subroutine
    end interface

    interface
        subroutine torch_tensor_to_array_cpp( &
            handle, host_ptr, dev_ptr, arr_rank, arr_shape, elem_size) &
            bind(c, name="torch_tensor_to_array_cpp")

            import c_ptr, c_int
            type(c_ptr),    intent(in),   value :: handle
            type(c_ptr),    intent(out)         :: host_ptr
            type(c_ptr),    intent(out)         :: dev_ptr
            integer(c_int), intent(in),   value :: arr_rank
            integer(c_int), intent(inout)       :: arr_shape(arr_rank)
            integer(c_int), intent(in),   value :: elem_size
        end subroutine
    end interface

    interface
        subroutine torch_tensor_free_cpp(handle) &
            bind(c, name="torch_tensor_free_cpp")
            
            import c_ptr
            type(c_ptr), intent(in), value :: handle
        end subroutine
    end interface

    ! Private routines

#ifdef _OPENACC
    interface
        type(c_devptr) function torch_helper_ptr_to_devptr_cpp(ptr) &
            bind(c, name="torch_helper_ptr_to_devptr_cpp")
            
            import c_ptr
            type(c_ptr), intent(in), value :: ptr
        end function
    end interface
#endif

    !!======================================================================================
    !! Tensor wrap-related C bindings
    !!======================================================================================

    interface
        subroutine torch_tensor_wrap_create_cpp(handle) &
            bind(c, name="torch_tensor_wrap_create_cpp")
            
            import c_ptr
            type(c_ptr), intent(out) :: handle
        end subroutine
    end interface

    interface
        subroutine torch_tensor_wrap_add_tensor_cpp(handle, h_tensor) &
            bind(c, name="torch_tensor_wrap_add_tensor_cpp")
            
            import c_ptr
            type(c_ptr), intent(in), value :: handle
            type(c_ptr), intent(in), value :: h_tensor
        end subroutine
    end interface

    interface
        subroutine torch_tensor_wrap_add_scalar_cpp(handle, p_value, elem_type, elem_size) &
            bind(c, name="torch_tensor_wrap_add_scalar_cpp")
            
            import c_ptr, c_int
            type(c_ptr),    intent(in), value :: handle
            type(c_ptr),    intent(in), value :: p_value
            integer(c_int), intent(in), value :: elem_type
            integer(c_int), intent(in), value :: elem_size
        end subroutine
    end interface

    interface
        subroutine torch_tensor_wrap_add_array_cpp( &
            handle, array, arr_rank, arr_shape, elem_type, elem_size) &
            bind(c, name="torch_tensor_wrap_add_array_cpp")
            
            import c_ptr, c_int
            type(c_ptr),    intent(in), value :: handle
            type(c_ptr),    intent(in), value :: array
            integer(c_int), intent(in), value :: arr_rank
            integer(c_int), intent(in)        :: arr_shape(arr_rank)
            integer(c_int), intent(in), value :: elem_type
            integer(c_int), intent(in), value :: elem_size
        end subroutine
    end interface

    interface
        subroutine torch_tensor_wrap_clear_cpp(handle) &
            bind(c, name="torch_tensor_wrap_clear_cpp")
            
            import c_ptr
            type(c_ptr), intent(in), value :: handle
        end subroutine
    end interface

    interface
        subroutine torch_tensor_wrap_free_cpp(handle) &
            bind(c, name="torch_tensor_wrap_free_cpp")
            
            import c_ptr
            type(c_ptr), intent(in), value :: handle
        end subroutine
    end interface

    contains

    !!======================================================================================
    !! Module member subroutines
    !!======================================================================================

    subroutine torch_module_load(this, file_name, flags)
        class(torch_module), intent(out) :: this
        character(len=*),    intent(in)  :: file_name
        integer, optional,   intent(in)  :: flags

        integer :: actual_flags
        
        actual_flags = 0
        if (present(flags)) then
            actual_flags = flags
        end if

        call torch_module_load_cpp(this%handle, file_name//c_null_char, actual_flags)
    end subroutine

    subroutine torch_module_save(this, file_name)
        class(torch_module), intent(in) :: this
        character(len=*),    intent(in) :: file_name
        
        call torch_module_save_cpp(this%handle, file_name//c_null_char)
    end subroutine

    subroutine torch_module_forward(this, inputs, output, flags)
        class(torch_module),     intent(inout)   :: this
        type(torch_tensor_wrap), intent(in)      :: inputs
        type(torch_tensor),      intent(inout)   :: output
        integer, optional,       intent(in)      :: flags

        integer :: actual_flags
        
        actual_flags = 0
        if (present(flags)) then
            actual_flags = flags
        end if

        call torch_module_forward_cpp(this%handle, inputs%handle, output%handle, actual_flags)
    end subroutine

    subroutine torch_module_train(this, inputs, target, loss)
        class(torch_module),     intent(inout) :: this
        type(torch_tensor_wrap), intent(in)    :: inputs
        type(torch_tensor),      intent(in)    :: target
        real(real32),            intent(out)   :: loss

        call torch_module_train_cpp(this%handle, inputs%handle, target%handle, this%h_optimizer, loss)
    end subroutine

    subroutine torch_module_create_optimizer_sgd(this, lr)
        class(torch_module), intent(inout) :: this
        real(real32),        intent(in)    :: lr

        call torch_optimizer_create_sgd_cpp(this%h_optimizer, this%handle, lr)
    end subroutine

    subroutine torch_module_free(this)
        type(torch_module) :: this

        call torch_module_free_cpp(this%handle)
    end subroutine

    !!======================================================================================
    !! PyModule member subroutines
    !!======================================================================================

    subroutine torch_pymodule_load(this, file_name)
        class(torch_pymodule), intent(inout) :: this
        character(len=*),      intent(in)    :: file_name

        call torch_pymodule_load_cpp(this%handle, file_name//c_null_char)
    end subroutine

    subroutine torch_pymodule_save(this, file_name)
        class(torch_pymodule), intent(in) :: this
        character(len=*),    intent(in)   :: file_name
        
        call torch_pymodule_save_cpp(this%handle, file_name//c_null_char)
    end subroutine

    subroutine torch_pymodule_forward(this, inputs, output)
        class(torch_pymodule),   intent(inout)   :: this
        type(torch_tensor_wrap), intent(in)      :: inputs
        type(torch_tensor),      intent(inout)   :: output

        call torch_pymodule_forward_cpp(this%handle, inputs%handle, output%handle)
    end subroutine

    function torch_pymodule_train(this, inputs, target, loss) result(is_completed)
        class(torch_pymodule),   intent(inout) :: this
        type(torch_tensor_wrap), intent(in)    :: inputs
        type(torch_tensor),      intent(in)    :: target
        real(real32), intent(out)              :: loss
        logical                                :: is_completed

        logical(c_bool) :: temp

        call torch_pymodule_train_cpp(this%handle, inputs%handle, target%handle, temp, loss)
        is_completed = logical(temp)
    end function

    subroutine torch_pymodule_free(this)
        type(torch_pymodule) :: this

        call torch_pymodule_free_cpp(this%handle)
    end subroutine

    !!======================================================================================
    !! Tensor member subroutines
    !!======================================================================================
    function torch_tensor_get_handle(this) result(ptr)
        class(torch_tensor), intent(inout) :: this
        type(c_ptr)                        :: ptr

        ptr = this%handle
    end function
    
    subroutine torch_tensor_free(this)
        type(torch_tensor) :: this

        integer(c_int8_t) , pointer :: dummy(:)

#ifdef _OPENACC
        if (this%is_acc_mapped) then
            call c_f_pointer(this%host_ptr, dummy, (/this%acc_mapped_size/))
            call acc_unmap_data(dummy)
        end if
#endif
        call torch_tensor_free_cpp(this%handle)
    end subroutine

    !!======================================================================================
    !! Tensor wrap member subroutines
    !!======================================================================================
    
    subroutine torch_tensor_wrap_create(this)
        class(torch_tensor_wrap), intent(inout) :: this

        call torch_tensor_wrap_create_cpp(this%handle)
    end subroutine

    subroutine torch_tensor_wrap_add_tensor(this, tensor)
        class(torch_tensor_wrap), intent(inout) :: this
        type(torch_tensor),       intent(in)    :: tensor

        call torch_tensor_wrap_add_tensor_cpp(this%handle, tensor%handle)
    end subroutine

    subroutine torch_tensor_wrap_clear(this)
        class(torch_tensor_wrap), intent(inout) :: this

        call torch_tensor_wrap_clear_cpp(this%handle)
    end subroutine

    subroutine torch_tensor_wrap_free(this)
        type(torch_tensor_wrap), intent(inout) :: this

        call torch_tensor_wrap_free_cpp(this%handle)
    end subroutine

    !!======================================================================================
    !! Tensor and tensor wrap member - generated subroutines for rank/datatype permutations
    !!======================================================================================

<<% dtype, dims
    subroutine torch_tensor_from_{dims.rank}_{dtype.name}(this, array)
        class(torch_tensor),      intent(inout)                  :: this
        {dtype.fortran_id} ({dtype.fortran_prec}), intent(in), target, contiguous :: array({dims.shape})

        this%is_acc_mapped = .false.
        this%acc_mapped_size = 0
        call torch_tensor_from_array_cpp(this%handle, &
            c_loc(array), size(shape(array)), shape(array), {dtype.c_id}, {dtype.size})
    end subroutine
    subroutine torch_tensor_to_{dims.rank}_{dtype.name}(this, array)
        class(torch_tensor),      intent(inout)        :: this
        {dtype.fortran_id} ({dtype.fortran_prec}), intent(out), pointer :: array({dims.shape})

        type(c_ptr) :: host_ptr
        type(c_ptr) :: dev_ptr
        integer :: arr_shape({dims.rank})

        call torch_tensor_to_array_cpp(this%handle, host_ptr, dev_ptr, {dims.rank}, arr_shape, {dtype.size})

#ifdef _OPENACC
        call c_f_pointer(host_ptr, array, arr_shape)
        if (c_associated(dev_ptr)) then
            this%is_acc_mapped = .true.
            this%acc_mapped_size = product(arr_shape) * {dtype.size}
            this%host_ptr = host_ptr
            this%dev_ptr  = dev_ptr
            call acc_map_data(array, torch_helper_ptr_to_devptr_cpp(dev_ptr), this%acc_mapped_size)
        end if
#else
        if (c_associated(dev_ptr)) then
            call c_f_pointer(dev_ptr, array, arr_shape)
        else
            call c_f_pointer(host_ptr, array, arr_shape)
        end if
#endif
    end subroutine

    subroutine torch_tensor_wrap_add_array_{dims.rank}_{dtype.name}(this, array)
        class(torch_tensor_wrap), intent(inout)             :: this
        {dtype.fortran_id} ({dtype.fortran_prec}),     intent(in), target, contiguous :: array({dims.shape})

        call torch_tensor_wrap_add_array_cpp(this%handle, &
            c_loc(array), size(shape(array)), shape(array), {dtype.c_id}, {dtype.size})
    end subroutine
%>>

<<% (dtype)
    subroutine torch_tensor_wrap_add_scalar_{dtype.name}(this, value)
        class(torch_tensor_wrap), intent(inout) :: this
        {dtype.fortran_id} ({dtype.fortran_prec}), intent(in), target    :: value

        call torch_tensor_wrap_add_scalar_cpp(this%handle, c_loc(value), {dtype.c_id}, {dtype.size})
    end subroutine
%>>

end module
